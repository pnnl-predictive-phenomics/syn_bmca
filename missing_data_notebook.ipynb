{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code from hackett (for reference only)\n",
    "### see: https://github.com/pnnl-predictive-phenomics/emll/blob/hackett_methods/notebooks/run_hackett_inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run the ADVI inference with a near-genome scale model and relative\n",
    "# omics data.\n",
    "\n",
    "# So I've found that for certain hardware (the intel chips on the cluster here,\n",
    "# for instance) the intel python and mkl-numpy are about 2x as fast as the\n",
    "# openblas versions. You can delete a bunch of this stuff if it doesn't work\n",
    "# for you. This example is a lot slower than some of the other ones though, but\n",
    "# I guess that's expected\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as T\n",
    "import cobra\n",
    "import emll\n",
    "from emll.util import initialize_elasticity\n",
    "\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "# Load model and data\n",
    "model = cobra.io.load_yaml_model(\"data/jol2012.yaml\")\n",
    "\n",
    "r_compartments = [r.compartments if \"e\" not in r.compartments else \"t\" for r in model.reactions]\n",
    "\n",
    "r_compartments[model.reactions.index(\"SUCCt2r\")] = \"c\"\n",
    "r_compartments[model.reactions.index(\"ACt2r\")] = \"c\"\n",
    "\n",
    "for rxn in model.exchanges:\n",
    "    r_compartments[model.reactions.index(rxn)] = \"t\"\n",
    "\n",
    "m_compartments = [m.compartment for m in model.metabolites]\n",
    "\n",
    "v_star = pd.read_csv(\"data/v_star.csv\", header=None, index_col=0)[1]\n",
    "\n",
    "x = pd.read_csv(\"data/metabolite_concentrations.csv\", index_col=0)\n",
    "v = pd.read_csv(\"data/boundary_fluxes.csv\", index_col=0)\n",
    "e = pd.read_csv(\"data/enzyme_measurements.csv\", index_col=0)\n",
    "\n",
    "# Reindex arrays to have the same column ordering\n",
    "to_consider = v.columns\n",
    "v = v.loc[:, to_consider]\n",
    "x = x.loc[:, to_consider]\n",
    "e = e.loc[:, to_consider]\n",
    "\n",
    "n_exp = len(to_consider) - 1\n",
    "ref_state = \"P0.11\"\n",
    "\n",
    "xn = (x.subtract(x[\"P0.11\"], 0) * np.log(2)).T\n",
    "en = (2 ** e.subtract(e[\"P0.11\"], 0)).T\n",
    "\n",
    "# To calculate vn, we have to merge in the v_star series and do some\n",
    "# calculations.\n",
    "v_star_df = pd.DataFrame(v_star).reset_index().rename(columns={0: \"id\", 1: \"flux\"})\n",
    "v_merge = v.merge(v_star_df, left_index=True, right_on=\"id\").set_index(\"id\")\n",
    "vn = v_merge.divide(v_merge.flux, axis=0).drop(\"flux\", axis=1).T\n",
    "\n",
    "# Drop reference state\n",
    "vn = vn.drop(ref_state)\n",
    "xn = xn.drop(ref_state)\n",
    "en = en.drop(ref_state)\n",
    "\n",
    "# Get indexes for measured values\n",
    "x_inds = np.array([model.metabolites.index(met) for met in xn.columns])\n",
    "e_inds = np.array([model.reactions.index(rxn) for rxn in en.columns])\n",
    "v_inds = np.array([model.reactions.index(rxn) for rxn in vn.columns])\n",
    "\n",
    "e_laplace_inds = []\n",
    "e_zero_inds = []\n",
    "\n",
    "for i, rxn in enumerate(model.reactions):\n",
    "    if rxn.id not in en.columns:\n",
    "        if (\"e\" not in rxn.compartments) and (len(rxn.compartments) == 1):\n",
    "            e_laplace_inds += [i]\n",
    "        else:\n",
    "            e_zero_inds += [i]\n",
    "\n",
    "e_laplace_inds = np.array(e_laplace_inds)\n",
    "e_zero_inds = np.array(e_zero_inds)\n",
    "e_indexer = np.hstack([e_inds, e_laplace_inds, e_zero_inds]).argsort()\n",
    "\n",
    "N = cobra.util.create_stoichiometric_matrix(model)\n",
    "Ex = emll.util.create_elasticity_matrix(model)\n",
    "Ey = emll.util.create_Ey_matrix(model)\n",
    "\n",
    "Ex *= 0.1 + 0.8 * np.random.rand(*Ex.shape)\n",
    "\n",
    "ll = emll.LinLogLeastNorm(N, Ex, Ey, v_star.values, driver=\"gelsy\")\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# Define the probability model\n",
    "\n",
    "with pm.Model() as pymc_model:\n",
    "    # Priors on elasticity values\n",
    "    Ex_t = pm.Deterministic(\n",
    "        \"Ex\",\n",
    "        initialize_elasticity(\n",
    "            ll.N,\n",
    "            b=0.01,\n",
    "            sigma=1,\n",
    "            alpha=None,\n",
    "            m_compartments=m_compartments,\n",
    "            r_compartments=r_compartments,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    Ey_t = T.as_tensor_variable(Ey)\n",
    "\n",
    "    e_measured = pm.Normal(\"log_e_measured\", mu=np.log(en), sigma=0.2, shape=(n_exp, len(e_inds)))\n",
    "    e_unmeasured = pm.Laplace(\"log_e_unmeasured\", mu=0, b=0.1, shape=(n_exp, len(e_laplace_inds)))\n",
    "    log_en_t = T.concatenate(\n",
    "        [e_measured, e_unmeasured, T.zeros((n_exp, len(e_zero_inds)))], axis=1\n",
    "    )[:, e_indexer]\n",
    "\n",
    "    pm.Deterministic(\"log_en_t\", log_en_t)\n",
    "\n",
    "    # Priors on external concentrations\n",
    "    yn_t = pm.Normal(\n",
    "        \"yn_t\", mu=0, sigma=10, shape=(n_exp, ll.ny), initval=0.1 * np.random.randn(n_exp, ll.ny)\n",
    "    )\n",
    "\n",
    "    chi_ss, vn_ss = ll.steady_state_pytensor(Ex_t, Ey_t, T.exp(log_en_t), yn_t)\n",
    "    pm.Deterministic(\"chi_ss\", chi_ss)\n",
    "    pm.Deterministic(\"vn_ss\", vn_ss)\n",
    "\n",
    "    log_vn_ss = T.log(T.clip(vn_ss[:, v_inds], 1e-8, 1e8))\n",
    "    log_vn_ss = T.clip(log_vn_ss, -1.5, 1.5)\n",
    "\n",
    "    chi_clip = T.clip(chi_ss[:, x_inds], -1.5, 1.5)\n",
    "\n",
    "    chi_obs = pm.Normal(\"chi_obs\", mu=chi_clip, sigma=0.2, observed=xn.clip(lower=-1.5, upper=1.5))\n",
    "    log_vn_obs = pm.Normal(\n",
    "        \"vn_obs\", mu=log_vn_ss, sigma=0.1, observed=np.log(vn).clip(lower=-1.5, upper=1.5)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a probablistic programming problem where we want to utilize different data types for a biological modeling of Bayesian metabolic control analysis with elasticities.\n",
    "There are different observation types, with each observation type having a set of model variables (like metabolite concentrations) measured and multiple experimental conditions (i.e. protocol A, protocol B, etc.). The tricky part is that for the different observation types, we don't necessarily have an intersection of experimental conditions - meaning we don't necessarily have the same conditions studied for different observations. Similarly, for a given observation time, certain variables may not have been observed for certain conditions. \n",
    "Essentially, there are 2 sources of missing information - missing conditions and missing model variable observations across the different observation types and experiments. \n",
    "\n",
    "We want to create a function that we can use with pyMC and pyTensor that will help us set up the Bayesian priors. \n",
    "\n",
    "The idea is that we first input a dataframe that contains all the conditions across all observation types and all the model variables for a particular observation type.\n",
    "In the data frame the values will be either the observed quantity (i.e. a float), a '0' if this variable should not be included in the bayesian model, and a 'NaN' if the variable was not observed but we want to potentially included it in the model.\n",
    "\n",
    "For model variables that have an observed quantity for a given condition, we assign a normal prior, Normal(0,1).\n",
    "For model variables that have a 0 value for a given condition, we assign a 0 for the prior - i.e. it's not in the model. \n",
    "For model variables that have a 'NaN' value for a given condition, we assign a Laplace prior. \n",
    "\n",
    "We should create a mapping or list of indexes so we can track which model variable and condition has which quantitiy and prior. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: ('condition_A', 'variable_x'), Variable: variable_x, Condition: condition_A, Value: 1.2, Prior: normal_rv{0, (0, 0), floatX, False}.out\n",
      "Index: ('condition_A', 'variable_y'), Variable: variable_y, Condition: condition_A, Value: 0.0, Prior: 0\n",
      "Index: ('condition_A', 'variable_z'), Variable: variable_z, Condition: condition_A, Value: nan, Prior: laplace_rv{0, (0, 0), floatX, False}.out\n",
      "Index: ('condition_B', 'variable_x'), Variable: variable_x, Condition: condition_B, Value: 0.0, Prior: 0\n",
      "Index: ('condition_B', 'variable_y'), Variable: variable_y, Condition: condition_B, Value: 2.3, Prior: normal_rv{0, (0, 0), floatX, False}.out\n",
      "Index: ('condition_B', 'variable_z'), Variable: variable_z, Condition: condition_B, Value: 0.0, Prior: 0\n",
      "Index: ('condition_C', 'variable_x'), Variable: variable_x, Condition: condition_C, Value: nan, Prior: laplace_rv{0, (0, 0), floatX, False}.out\n",
      "Index: ('condition_C', 'variable_y'), Variable: variable_y, Condition: condition_C, Value: nan, Prior: laplace_rv{0, (0, 0), floatX, False}.out\n",
      "Index: ('condition_C', 'variable_z'), Variable: variable_z, Condition: condition_C, Value: 3.4, Prior: normal_rv{0, (0, 0), floatX, False}.out\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "\n",
    "def set_priors(df: pd.DataFrame):\n",
    "    '''Set priors in dataframe based on model variable value for a given condition.'''\n",
    "    priors = []\n",
    "    index_map = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        for j, value in enumerate(row):\n",
    "            if pd.isnull(value):  # NaN value\n",
    "                prior = pm.Laplace.dist(mu=0, b=1)\n",
    "            elif value == 0:  # Zero value\n",
    "                prior = 0\n",
    "            else:  # Observed quantity\n",
    "                prior = pm.Normal.dist(mu=0, sigma=1)\n",
    "\n",
    "            priors.append(prior)\n",
    "            index_map.append((i, df.columns[j]))\n",
    "\n",
    "    return priors, index_map\n",
    "\n",
    "# Create a test dataframe\n",
    "df = pd.DataFrame({\n",
    "    'variable_x': [1.2, 0, np.nan],\n",
    "    'variable_y': [0, 2.3, np.nan],\n",
    "    'variable_z': [np.nan, 0, 3.4]\n",
    "}, index=['condition_A', 'condition_B', 'condition_C'])\n",
    "\n",
    "# Run the function\n",
    "priors, index_map = set_priors(df)\n",
    "\n",
    "# Print the results\n",
    "for index, prior in zip(index_map, priors):\n",
    "    condition_name, variable_name = index\n",
    "    value = df.at[condition_name, variable_name]\n",
    "    print(f'Index: {index}, Variable: {variable_name}, Condition: {condition_name}, Value: {value}, Prior: {prior}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syn_bmca_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
